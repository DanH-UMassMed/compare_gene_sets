{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages we will need\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Wormbase GeneIDs\n",
    "This file is exported from wormbase.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids_df = pd.read_csv('./data/WS289.geneIDs.csv') \n",
    "gene_ids_df.set_index('Wormbase_Id', inplace=True)\n",
    "gene_ids_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Excel file to work with\n",
    "* This file should have alteast one \"Tab\"\n",
    "* And the first column of the sheet should have Wormbase IDs\n",
    "\n",
    "========\n",
    "* The column layout is as follows: \n",
    "* `ID,\tSequence_Name,\tGene_Name`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Excel with the Gene Sets of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Candidate_Genes extracted from from Brendans Spreadsheet\n",
    "\n",
    "xlsx_file_nm = './data/KB_stress gene expression.xlsx'\n",
    "genes_xlsx = pd.ExcelFile(xlsx_file_nm)\n",
    "sheet_names = genes_xlsx.sheet_names\n",
    "sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the dataframes to a dictionary keyed by the sheet name\n",
    "genes_dfs = {}\n",
    "for sheet_name in sheet_names:\n",
    "    sheet_df = pd.read_excel(xlsx_file_nm, sheet_name=sheet_name)\n",
    "    genes_dfs[sheet_name] = sheet_df\n",
    "#genes_dfs\n",
    "genes_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Gene_Names with those from Wormbase to ensure they are correct\n",
    "\n",
    "for sheet_name in genes_dfs.keys():\n",
    "    sheet_df = genes_dfs[sheet_name]\n",
    "    # Drop the empty Gene_Name column\n",
    "    sheet_df.drop(columns='Sequence_Name', inplace=True)\n",
    "    sheet_df.drop(columns='Gene_Name', inplace=True)\n",
    "    # Add Gene_Name from the Wormbase geneIDs list\n",
    "    sheet_df.set_index('ID', inplace=True)\n",
    "    sheet_df = pd.merge(sheet_df, gene_ids_df[['Sequence_id']], left_index=True, right_index=True)\n",
    "    sheet_df = pd.merge(sheet_df, gene_ids_df[['Gene_name']], left_index=True, right_index=True)\n",
    "    genes_dfs[sheet_name] = sheet_df \n",
    "#genes_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the UP and Down Genes to Compare against\n",
    "* The should be the output from DE Seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_genes_df = pd.read_csv('./data/N2_PQ_DOWN.csv') \n",
    "down_genes_df = pd.read_csv('./data/N2_PQ_UP.csv') \n",
    "up_down_genes_df = pd.concat([up_genes_df, down_genes_df])\n",
    "\n",
    "print(len(up_down_genes_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and save the Venn Diagram\n",
    "\n",
    "def venn_plot(set1_df, set2_df, set3_dfs, names, filename):\n",
    "    print(names)\n",
    "    print(names[2])\n",
    "    set1 = set1_df['ID']\n",
    "    print(len(set1))\n",
    "    set2 = set2_df['ID']\n",
    "    print(len(set2))\n",
    "    print(set3_dfs.keys())\n",
    "    print(names[2] in set3_dfs.keys())\n",
    "    set3_df = set3_dfs[str(names[2])]\n",
    "    print(set3_df)\n",
    "    set3 = set3_df.index\n",
    "    print(len(set3))\n",
    "    \n",
    "    \n",
    "    # Convert Series to sets\n",
    "    set1 = set(set1)\n",
    "    set2 = set(set2)\n",
    "    set3 = set(set3)\n",
    "\n",
    "    # Create the Venn diagram\n",
    "    venn = venn3([set1, set2, set3], names)\n",
    "\n",
    "    # Add commas to numbers and set them as labels for the circles\n",
    "    #venn.get_label_by_id('100').set_text(f\"{len(set1):,}\")\n",
    "    #venn.get_label_by_id('010').set_text(f\"{len(set2):,}\")\n",
    "    #venn.get_label_by_id('001').set_text(f\"{len(set3):,}\")\n",
    "\n",
    "    # Save the plot\n",
    "    plt.title(f\"Venn Diagram {names[0]}, {names[1]} and {names[2]}\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the overlaping genes and create a column in the dataframe representing the overlap\n",
    "\n",
    "def find_overlap(set1_df, set2_df, set3_dfs, names, filename):\n",
    "    set1 = set1_df['ID']\n",
    "    set2 = set2_df['ID']\n",
    "    set3 = set3_dfs[names[2]].index\n",
    "\n",
    "    # Convert Pandas Series to sets\n",
    "    set1 = set(set1)\n",
    "    set2 = set(set2)\n",
    "    set3 = set(set3)\n",
    "\n",
    "    # Find elements that overlap between Set1 and Set3\n",
    "    overlap_set1_set3 = set1.intersection(set3)\n",
    "\n",
    "    # Find elements that overlap between Set2 and Set3\n",
    "    overlap_set2_set3 = set2.intersection(set3)\n",
    "\n",
    "    # Find elements that overlap between Set1, Set2 and Set3\n",
    "    overlap_all_sets = set1.intersection(set2, set3)\n",
    "\n",
    "    set3_dfs[names[2]][names[0]] = set3_dfs[names[2]].index.isin(overlap_set1_set3)\n",
    "    set3_dfs[names[2]][names[1]] = set3_dfs[names[2]].index.isin(overlap_set2_set3)\n",
    "    set3_dfs[names[2]]['Both'] = set3_dfs[names[2]].index.isin(overlap_all_sets)\n",
    "    \n",
    "    set3_dfs[names[2]] = set3_dfs[names[2]].sort_values(by=['Both', names[1], names[0]], ascending=[False, False, False])\n",
    "\n",
    "    \n",
    "    return set3_dfs[names[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the Cells of interest and Autofit the columns\n",
    "\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "def highlight_rows_by_column(worksheet, column_number, color):\n",
    "    color_fill = PatternFill(start_color=color, end_color=color, fill_type='solid')\n",
    "    df = pd.DataFrame(worksheet.values)\n",
    "    for row_idx, row in enumerate(df.itertuples(), start=1):\n",
    "        if isinstance(row[column_number], bool) and row[column_number] is True:  # Check if the column value is True\n",
    "            for col_idx in range(1, len(row)):\n",
    "                worksheet.cell(row=row_idx, column=col_idx).fill = color_fill\n",
    "\n",
    "def autofit_columns(worksheet):\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column = [cell for cell in column]\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2) * 1.2  # Adding some extra padding\n",
    "        worksheet.column_dimensions[get_column_letter(column[0].column)].width = adjusted_width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it all together and generate the output\n",
    "from openpyxl import Workbook\n",
    "\n",
    "excel_file_path = \"./data/Genes_Overlap1.xlsx\"\n",
    "if os.path.exists(excel_file_path):\n",
    "    os.remove(excel_file_path)\n",
    "\n",
    "# Create a new workbook\n",
    "workbook = Workbook()\n",
    "\n",
    "# Remove the default \"Sheet\" created by openpyxl\n",
    "#default_sheet = workbook['Sheet']\n",
    "#workbook.remove(default_sheet)\n",
    "\n",
    "with pd.ExcelWriter(excel_file_path, engine='openpyxl') as writer:\n",
    "    #writer.book = Workbook()\n",
    "    for sheet_name in sheet_names:\n",
    "        names = ('N2_PQ_Up', 'N2_PQ_Down', sheet_name)\n",
    "        filename = f\"./data/venn_{sheet_name}.png\"    \n",
    "        plot = venn_plot(up_genes_df, down_genes_df, genes_dfs, names, filename)\n",
    "        sheet_df = find_overlap(up_genes_df, down_genes_df, genes_dfs, names, filename)\n",
    "        sheet_df.to_excel(writer, sheet_name=sheet_name, index=True, index_label='ID')\n",
    "        \n",
    "    # Autofit and highlight columns for each sheet\n",
    "    for sheet in writer.sheets.values():\n",
    "        autofit_columns(sheet)\n",
    "        for index, color in  enumerate(['fde9d9','daeef3','e4dfec']):\n",
    "            highlight_rows_by_column(sheet, index+4, color)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows  # Importing dataframe_to_rows\n",
    "\n",
    "excel_file_path = './data/output.xlsx'\n",
    "\n",
    "# Create a DataFrame (example data)\n",
    "data = {'Column1': [1, 2, 3], 'Column2': ['A', 'B', 'C']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a Workbook instance using openpyxl\n",
    "workbook = Workbook()\n",
    "\n",
    "# Access the active sheet (or create a new sheet) in the workbook\n",
    "sheet = workbook.active\n",
    "\n",
    "# Write the DataFrame to the sheet in the workbook\n",
    "for r in dataframe_to_rows(df, index=False, header=True):\n",
    "    sheet.append(r)\n",
    "\n",
    "# Save the workbook to the desired file path\n",
    "workbook.save(excel_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Gene Names to Wormbase IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids_df = pd.read_csv('./data/WS289.geneIDs.csv') \n",
    "gene_names_df = pd.read_csv('./data/gene_names.csv')\n",
    "\n",
    "print(gene_ids_df.columns[1])\n",
    "print(gene_names_df.columns[0])\n",
    "print(gene_ids_df.columns[1]==gene_names_df.columns[0])\n",
    "print(len(gene_names_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match Sequence Ids that are in the Gene_name Column\n",
    "merged_df = pd.merge(gene_names_df, gene_ids_df, left_on='Gene_name', right_on='Sequence_id', how='left')\n",
    "columns_to_drop = ['Gene_name_y', 'Sequence_id','Gene_Type']\n",
    "merged_df = merged_df.drop(columns=columns_to_drop)\n",
    "merged_df = merged_df.rename(columns={'Gene_name_x': 'Gene_name'})\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the Gene_names that are in the Gene_name Column\n",
    "merged_df1 = pd.merge(merged_df, gene_ids_df, left_on='Gene_name', right_on='Gene_name', how='left')\n",
    "merged_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combimed the Wormbase_Id Ids the Matched above into a Single Column \n",
    "merged_df1['Wormbase_Id'] = merged_df1['Wormbase_Id_x']\n",
    "merged_df1.loc[merged_df['Wormbase_Id'].isnull(), 'Wormbase_Id'] = merged_df1['Wormbase_Id_y']\n",
    "merged_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop an rows that still have null values and save\n",
    "has_values = merged_df1[~merged_df1['Wormbase_Id'].isnull()]\n",
    "has_values.to_csv('./data/has_values.csv')\n",
    "has_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the remaining rows that do not have Wormbase IDs\n",
    "nan_values = merged_df1[merged_df1['Wormbase_Id'].isnull()]\n",
    "print(len(nan_values))\n",
    "nan_values['Gene_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
